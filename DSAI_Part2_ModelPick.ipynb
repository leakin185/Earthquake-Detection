{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science and Artificial Intelligence Mini Project\n",
    "## Part 2: Model Selection\n",
    "### Team members: Jamie Sze, Tan Jie Hui, Wang Yi\n",
    "\n",
    "In this section, we aim to evaluate different popular machine learning models and their accuracy in this particular use case of classifying earthquake damage. To do so, we will explore the use of 5 popular machine learning models, tune their hyperparameters to best fit our use case of multi-class classification and identify which model has the best accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents <a class=\"anchor\" id=\"top\"></a>\n",
    "\n",
    "#### [Import Libraries and Datasets](#import)\n",
    "\n",
    "#### [Data Preparation](#dataprep)\n",
    "- [One Hot Encoding](#ohe)\n",
    "- [Features and Labels](#features)\n",
    "- [Splitting Dataset Into Train and Test](#split)\n",
    "\n",
    "#### [Modelling and Classification](#model)\n",
    "- [Model 1: Artificial Neural Network](#model1)\n",
    "- [Model 2: Logistics Regression Classifier](#model2)\n",
    "- [Model 3: K Nearest Neighbours](#model3)\n",
    "- [Model 4: Decision Tree](#model4)\n",
    "- [Model 5: Random Forest Classifier](#model5)\n",
    "\n",
    "#### [Model Selection](#select)\n",
    "\n",
    "#### [Appendix](#appendix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries <a class=\"anchor\" id=\"import\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Basic Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt # we only need pyplot\n",
    "sb.set() # set the default Seaborn style for graphics\n",
    "from scipy import stats\n",
    "import sklearn.metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import seaborn as sn\n",
    "import tensorflow as tf\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features of Buildings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>geo_level_1_id</th>\n",
       "      <th>geo_level_2_id</th>\n",
       "      <th>geo_level_3_id</th>\n",
       "      <th>count_floors_pre_eq</th>\n",
       "      <th>age</th>\n",
       "      <th>area_percentage</th>\n",
       "      <th>height_percentage</th>\n",
       "      <th>land_surface_condition</th>\n",
       "      <th>foundation_type</th>\n",
       "      <th>...</th>\n",
       "      <th>has_secondary_use_agriculture</th>\n",
       "      <th>has_secondary_use_hotel</th>\n",
       "      <th>has_secondary_use_rental</th>\n",
       "      <th>has_secondary_use_institution</th>\n",
       "      <th>has_secondary_use_school</th>\n",
       "      <th>has_secondary_use_industry</th>\n",
       "      <th>has_secondary_use_health_post</th>\n",
       "      <th>has_secondary_use_gov_office</th>\n",
       "      <th>has_secondary_use_use_police</th>\n",
       "      <th>has_secondary_use_other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>802906</td>\n",
       "      <td>6</td>\n",
       "      <td>487</td>\n",
       "      <td>12198</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>28830</td>\n",
       "      <td>8</td>\n",
       "      <td>900</td>\n",
       "      <td>2812</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>o</td>\n",
       "      <td>r</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>94947</td>\n",
       "      <td>21</td>\n",
       "      <td>363</td>\n",
       "      <td>8973</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>590882</td>\n",
       "      <td>22</td>\n",
       "      <td>418</td>\n",
       "      <td>10694</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>201944</td>\n",
       "      <td>11</td>\n",
       "      <td>131</td>\n",
       "      <td>1488</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   building_id  geo_level_1_id  geo_level_2_id  geo_level_3_id  \\\n",
       "0       802906               6             487           12198   \n",
       "1        28830               8             900            2812   \n",
       "2        94947              21             363            8973   \n",
       "3       590882              22             418           10694   \n",
       "4       201944              11             131            1488   \n",
       "\n",
       "   count_floors_pre_eq  age  area_percentage  height_percentage  \\\n",
       "0                    2   30                6                  5   \n",
       "1                    2   10                8                  7   \n",
       "2                    2   10                5                  5   \n",
       "3                    2   10                6                  5   \n",
       "4                    3   30                8                  9   \n",
       "\n",
       "  land_surface_condition foundation_type  ... has_secondary_use_agriculture  \\\n",
       "0                      t               r  ...                             0   \n",
       "1                      o               r  ...                             0   \n",
       "2                      t               r  ...                             0   \n",
       "3                      t               r  ...                             0   \n",
       "4                      t               r  ...                             0   \n",
       "\n",
       "  has_secondary_use_hotel has_secondary_use_rental  \\\n",
       "0                       0                        0   \n",
       "1                       0                        0   \n",
       "2                       0                        0   \n",
       "3                       0                        0   \n",
       "4                       0                        0   \n",
       "\n",
       "  has_secondary_use_institution has_secondary_use_school  \\\n",
       "0                             0                        0   \n",
       "1                             0                        0   \n",
       "2                             0                        0   \n",
       "3                             0                        0   \n",
       "4                             0                        0   \n",
       "\n",
       "   has_secondary_use_industry  has_secondary_use_health_post  \\\n",
       "0                           0                              0   \n",
       "1                           0                              0   \n",
       "2                           0                              0   \n",
       "3                           0                              0   \n",
       "4                           0                              0   \n",
       "\n",
       "   has_secondary_use_gov_office  has_secondary_use_use_police  \\\n",
       "0                             0                             0   \n",
       "1                             0                             0   \n",
       "2                             0                             0   \n",
       "3                             0                             0   \n",
       "4                             0                             0   \n",
       "\n",
       "   has_secondary_use_other  \n",
       "0                        0  \n",
       "1                        0  \n",
       "2                        0  \n",
       "3                        0  \n",
       "4                        0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eqData_train = pd.read_csv('train_values.csv')\n",
    "eqData_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels of Buildings (Damage-Grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(260601, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv('train_labels.csv')\n",
    "labels.head()\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>damage_grade</th>\n",
       "      <th>geo_level_1_id</th>\n",
       "      <th>geo_level_2_id</th>\n",
       "      <th>geo_level_3_id</th>\n",
       "      <th>count_floors_pre_eq</th>\n",
       "      <th>age</th>\n",
       "      <th>area_percentage</th>\n",
       "      <th>height_percentage</th>\n",
       "      <th>land_surface_condition</th>\n",
       "      <th>...</th>\n",
       "      <th>has_secondary_use_agriculture</th>\n",
       "      <th>has_secondary_use_hotel</th>\n",
       "      <th>has_secondary_use_rental</th>\n",
       "      <th>has_secondary_use_institution</th>\n",
       "      <th>has_secondary_use_school</th>\n",
       "      <th>has_secondary_use_industry</th>\n",
       "      <th>has_secondary_use_health_post</th>\n",
       "      <th>has_secondary_use_gov_office</th>\n",
       "      <th>has_secondary_use_use_police</th>\n",
       "      <th>has_secondary_use_other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>802906</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>487</td>\n",
       "      <td>12198</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>28830</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>900</td>\n",
       "      <td>2812</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>o</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>94947</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>363</td>\n",
       "      <td>8973</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>590882</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>418</td>\n",
       "      <td>10694</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>201944</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>131</td>\n",
       "      <td>1488</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   building_id  damage_grade  geo_level_1_id  geo_level_2_id  geo_level_3_id  \\\n",
       "0       802906             3               6             487           12198   \n",
       "1        28830             2               8             900            2812   \n",
       "2        94947             3              21             363            8973   \n",
       "3       590882             2              22             418           10694   \n",
       "4       201944             3              11             131            1488   \n",
       "\n",
       "   count_floors_pre_eq  age  area_percentage  height_percentage  \\\n",
       "0                    2   30                6                  5   \n",
       "1                    2   10                8                  7   \n",
       "2                    2   10                5                  5   \n",
       "3                    2   10                6                  5   \n",
       "4                    3   30                8                  9   \n",
       "\n",
       "  land_surface_condition  ... has_secondary_use_agriculture  \\\n",
       "0                      t  ...                             0   \n",
       "1                      o  ...                             0   \n",
       "2                      t  ...                             0   \n",
       "3                      t  ...                             0   \n",
       "4                      t  ...                             0   \n",
       "\n",
       "  has_secondary_use_hotel has_secondary_use_rental  \\\n",
       "0                       0                        0   \n",
       "1                       0                        0   \n",
       "2                       0                        0   \n",
       "3                       0                        0   \n",
       "4                       0                        0   \n",
       "\n",
       "  has_secondary_use_institution has_secondary_use_school  \\\n",
       "0                             0                        0   \n",
       "1                             0                        0   \n",
       "2                             0                        0   \n",
       "3                             0                        0   \n",
       "4                             0                        0   \n",
       "\n",
       "  has_secondary_use_industry  has_secondary_use_health_post  \\\n",
       "0                          0                              0   \n",
       "1                          0                              0   \n",
       "2                          0                              0   \n",
       "3                          0                              0   \n",
       "4                          0                              0   \n",
       "\n",
       "   has_secondary_use_gov_office  has_secondary_use_use_police  \\\n",
       "0                             0                             0   \n",
       "1                             0                             0   \n",
       "2                             0                             0   \n",
       "3                             0                             0   \n",
       "4                             0                             0   \n",
       "\n",
       "   has_secondary_use_other  \n",
       "0                        0  \n",
       "1                        0  \n",
       "2                        0  \n",
       "3                        0  \n",
       "4                        0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = list(pd.read_csv(\"train_values.csv\", nrows =1))\n",
    "temp = pd.read_csv('train_values.csv',usecols =[i for i in cols if i != 'building_id'])\n",
    "\n",
    "eqData_train = pd.concat([labels, temp], axis = 1)\n",
    "eqData_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation <a class=\"anchor\" id=\"dataprep\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot-Encoding <a class=\"anchor\" id=\"ohe\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the features observed above, we have to extract those categorical features and encode them using a one-hot-encoded process. One hot encoding is a process by which categorical variables are converted into a form that could be provided to ML algorithms to do a better job in prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        building_id  damage_grade  geo_level_1_id  geo_level_2_id  \\\n",
      "0            802906             3               6             487   \n",
      "1             28830             2               8             900   \n",
      "2             94947             3              21             363   \n",
      "3            590882             2              22             418   \n",
      "4            201944             3              11             131   \n",
      "...             ...           ...             ...             ...   \n",
      "260596       688636             2              25            1335   \n",
      "260597       669485             3              17             715   \n",
      "260598       602512             3              17              51   \n",
      "260599       151409             2              26              39   \n",
      "260600       747594             3              21               9   \n",
      "\n",
      "        geo_level_3_id  count_floors_pre_eq  age  area_percentage  \\\n",
      "0                12198                    2   30                6   \n",
      "1                 2812                    2   10                8   \n",
      "2                 8973                    2   10                5   \n",
      "3                10694                    2   10                6   \n",
      "4                 1488                    3   30                8   \n",
      "...                ...                  ...  ...              ...   \n",
      "260596            1621                    1   55                6   \n",
      "260597            2060                    2    0                6   \n",
      "260598            8163                    3   55                6   \n",
      "260599            1851                    2   10               14   \n",
      "260600            9101                    3   10                7   \n",
      "\n",
      "        height_percentage  has_superstructure_adobe_mud  ...  \\\n",
      "0                       5                             1  ...   \n",
      "1                       7                             0  ...   \n",
      "2                       5                             0  ...   \n",
      "3                       5                             0  ...   \n",
      "4                       9                             1  ...   \n",
      "...                   ...                           ...  ...   \n",
      "260596                  3                             0  ...   \n",
      "260597                  5                             0  ...   \n",
      "260598                  7                             0  ...   \n",
      "260599                  6                             0  ...   \n",
      "260600                  6                             0  ...   \n",
      "\n",
      "        plan_configuration_m  plan_configuration_n  plan_configuration_o  \\\n",
      "0                          0                     0                     0   \n",
      "1                          0                     0                     0   \n",
      "2                          0                     0                     0   \n",
      "3                          0                     0                     0   \n",
      "4                          0                     0                     0   \n",
      "...                      ...                   ...                   ...   \n",
      "260596                     0                     0                     0   \n",
      "260597                     0                     0                     0   \n",
      "260598                     0                     0                     0   \n",
      "260599                     0                     0                     0   \n",
      "260600                     0                     0                     0   \n",
      "\n",
      "        plan_configuration_q  plan_configuration_s  plan_configuration_u  \\\n",
      "0                          0                     0                     0   \n",
      "1                          0                     0                     0   \n",
      "2                          0                     0                     0   \n",
      "3                          0                     0                     0   \n",
      "4                          0                     0                     0   \n",
      "...                      ...                   ...                   ...   \n",
      "260596                     1                     0                     0   \n",
      "260597                     0                     0                     0   \n",
      "260598                     0                     0                     0   \n",
      "260599                     0                     0                     0   \n",
      "260600                     0                     0                     0   \n",
      "\n",
      "        legal_ownership_status_a  legal_ownership_status_r  \\\n",
      "0                              0                         0   \n",
      "1                              0                         0   \n",
      "2                              0                         0   \n",
      "3                              0                         0   \n",
      "4                              0                         0   \n",
      "...                          ...                       ...   \n",
      "260596                         0                         0   \n",
      "260597                         0                         0   \n",
      "260598                         0                         0   \n",
      "260599                         0                         0   \n",
      "260600                         0                         0   \n",
      "\n",
      "        legal_ownership_status_v  legal_ownership_status_w  \n",
      "0                              1                         0  \n",
      "1                              1                         0  \n",
      "2                              1                         0  \n",
      "3                              1                         0  \n",
      "4                              1                         0  \n",
      "...                          ...                       ...  \n",
      "260596                         1                         0  \n",
      "260597                         1                         0  \n",
      "260598                         1                         0  \n",
      "260599                         1                         0  \n",
      "260600                         1                         0  \n",
      "\n",
      "[260601 rows x 70 columns]\n"
     ]
    }
   ],
   "source": [
    "categoricalcolumns = [\"land_surface_condition\", \"foundation_type\",\"roof_type\",\"ground_floor_type\",\"other_floor_type\",\"position\",\"plan_configuration\", \"legal_ownership_status\"]\n",
    "eqData_train = pd.get_dummies(eqData_train, columns= categoricalcolumns, prefix= categoricalcolumns)\n",
    "print(eqData_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(260601, 70)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eqData_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "building_id                 int64\n",
       "damage_grade                int64\n",
       "geo_level_1_id              int64\n",
       "geo_level_2_id              int64\n",
       "geo_level_3_id              int64\n",
       "                            ...  \n",
       "plan_configuration_u        uint8\n",
       "legal_ownership_status_a    uint8\n",
       "legal_ownership_status_r    uint8\n",
       "legal_ownership_status_v    uint8\n",
       "legal_ownership_status_w    uint8\n",
       "Length: 70, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eqData_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Dataset for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>damage_grade</th>\n",
       "      <th>geo_level_1_id</th>\n",
       "      <th>geo_level_2_id</th>\n",
       "      <th>geo_level_3_id</th>\n",
       "      <th>count_floors_pre_eq</th>\n",
       "      <th>age</th>\n",
       "      <th>area_percentage</th>\n",
       "      <th>height_percentage</th>\n",
       "      <th>has_superstructure_adobe_mud</th>\n",
       "      <th>...</th>\n",
       "      <th>plan_configuration_m</th>\n",
       "      <th>plan_configuration_n</th>\n",
       "      <th>plan_configuration_o</th>\n",
       "      <th>plan_configuration_q</th>\n",
       "      <th>plan_configuration_s</th>\n",
       "      <th>plan_configuration_u</th>\n",
       "      <th>legal_ownership_status_a</th>\n",
       "      <th>legal_ownership_status_r</th>\n",
       "      <th>legal_ownership_status_v</th>\n",
       "      <th>legal_ownership_status_w</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>802906</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>487</td>\n",
       "      <td>12198</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>28830</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>900</td>\n",
       "      <td>2812</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>94947</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>363</td>\n",
       "      <td>8973</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>590882</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>418</td>\n",
       "      <td>10694</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>201944</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>131</td>\n",
       "      <td>1488</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   building_id  damage_grade  geo_level_1_id  geo_level_2_id  geo_level_3_id  \\\n",
       "0       802906             3               6             487           12198   \n",
       "1        28830             2               8             900            2812   \n",
       "2        94947             3              21             363            8973   \n",
       "3       590882             2              22             418           10694   \n",
       "4       201944             3              11             131            1488   \n",
       "\n",
       "   count_floors_pre_eq  age  area_percentage  height_percentage  \\\n",
       "0                    2   30                6                  5   \n",
       "1                    2   10                8                  7   \n",
       "2                    2   10                5                  5   \n",
       "3                    2   10                6                  5   \n",
       "4                    3   30                8                  9   \n",
       "\n",
       "   has_superstructure_adobe_mud  ...  plan_configuration_m  \\\n",
       "0                             1  ...                     0   \n",
       "1                             0  ...                     0   \n",
       "2                             0  ...                     0   \n",
       "3                             0  ...                     0   \n",
       "4                             1  ...                     0   \n",
       "\n",
       "   plan_configuration_n  plan_configuration_o  plan_configuration_q  \\\n",
       "0                     0                     0                     0   \n",
       "1                     0                     0                     0   \n",
       "2                     0                     0                     0   \n",
       "3                     0                     0                     0   \n",
       "4                     0                     0                     0   \n",
       "\n",
       "   plan_configuration_s  plan_configuration_u  legal_ownership_status_a  \\\n",
       "0                     0                     0                         0   \n",
       "1                     0                     0                         0   \n",
       "2                     0                     0                         0   \n",
       "3                     0                     0                         0   \n",
       "4                     0                     0                         0   \n",
       "\n",
       "   legal_ownership_status_r  legal_ownership_status_v  \\\n",
       "0                         0                         1   \n",
       "1                         0                         1   \n",
       "2                         0                         1   \n",
       "3                         0                         1   \n",
       "4                         0                         1   \n",
       "\n",
       "   legal_ownership_status_w  \n",
       "0                         0  \n",
       "1                         0  \n",
       "2                         0  \n",
       "3                         0  \n",
       "4                         0  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eqData_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features <a class=\"anchor\" id=\"features\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Removing labels from feature dataset \n",
    "features = eqData_train\n",
    "\n",
    "###Removing unneccessary data from feature dataset \n",
    "features = features.drop(['building_id'],axis=1)\n",
    "features = features.drop(['damage_grade'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = eqData_train['damage_grade']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data into train and test containers <a class=\"anchor\" id=\"split\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_Y, test_Y = train_test_split(features,labels,test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[back to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling and Classification <a class=\"anchor\" id=\"model\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be testing out a 5 machine learning models on the train dataset and checking the accuracy of each model.\n",
    "1. Artificial Neural Network\n",
    "2. Logistics Regression Classifier\n",
    "3. K Nearest Neighbours\n",
    "4. Decision Tree\n",
    "5. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Artificial Neural Network <a class=\"anchor\" id=\"model1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Artificial Neural Network is a model that is inspired by the brain and tries to replicate the way that humans learn. It consists of one input layer, a few hidden layers, and one output layer, with each hidden layer analysing different features of the dataset. During the training stage, the algorithm will learn to detect features that are relevant to predicting the output (ie damage_grade). It can also make use of backpropagation to correct mistakes during the training process, thus improving the model.\n",
    "\n",
    "We will first employ the default ANN model. Later on, we will tune its activation function and loss function to improve accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def auc_roc(y_true, y_pred):\n",
    "    # any tensorflow metric\n",
    "    value, update_op = tf.contrib.metrics.streaming_auc(y_pred, y_true)\n",
    "\n",
    "    # find all variables created for this metric\n",
    "    metric_vars = [i for i in tf.local_variables() if 'auc_roc' in i.name.split('/')[1]]\n",
    "\n",
    "    # Add metric variables to GLOBAL_VARIABLES collection.\n",
    "    # They will be initialized for new session.\n",
    "    for v in metric_vars:\n",
    "        tf.add_to_collection(tf.GraphKeys.GLOBAL_VARIABLES, v)\n",
    "\n",
    "    # force to update metric values\n",
    "    with tf.control_dependencies([update_op]):\n",
    "        value = tf.identity(value)\n",
    "        return value\n",
    "\n",
    "    \n",
    "def f1(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "#     y_pred = K.round(y_pred > 0.5)\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "\n",
    "def matthewCoefficient(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "#     y_pred = K.round(y_pred > 0.5)\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "    matthewcoef = ((tp*tn) - (fp*fn))/ ((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))**0.5\n",
    "\n",
    "#     p = tp / (tp + fp + K.epsilon())\n",
    "#     r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "#     f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    matthewcoef = tf.where(tf.math.is_nan(matthewcoef), tf.zeros_like(matthewcoef), matthewcoef)\n",
    "    return K.mean(matthewcoef)\n",
    "\n",
    "\n",
    "def one_hot_encode_object_array(arr):\n",
    "    '''One hot encode a numpy array of objects (e.g. strings)'''\n",
    "    uniques, ids = np.unique(arr, return_inverse=True)\n",
    "    return np_utils.to_categorical(ids, len(uniques))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "208480/208480 [==============================] - 10s 46us/step - loss: 0.8871 - accuracy: 0.3347\n",
      "Epoch 2/30\n",
      "208480/208480 [==============================] - 10s 47us/step - loss: 0.8871 - accuracy: 0.3347\n",
      "Epoch 3/30\n",
      "208480/208480 [==============================] - 9s 41us/step - loss: 0.8190 - accuracy: 0.2601\n",
      "Epoch 4/30\n",
      "208480/208480 [==============================] - 9s 44us/step - loss: 0.6667 - accuracy: 0.0966\n",
      "Epoch 5/30\n",
      "208480/208480 [==============================] - 11s 51us/step - loss: 0.6667 - accuracy: 0.0966\n",
      "Epoch 6/30\n",
      "208480/208480 [==============================] - 10s 49us/step - loss: 0.6667 - accuracy: 0.09660s - loss: 0.6667 - \n",
      "Epoch 7/30\n",
      "208480/208480 [==============================] - 15s 70us/step - loss: 0.6667 - accuracy: 0.0966\n",
      "Epoch 8/30\n",
      "208480/208480 [==============================] - 12s 56us/step - loss: 0.6667 - accuracy: 0.0966\n",
      "Epoch 9/30\n",
      "208480/208480 [==============================] - 8s 41us/step - loss: 0.6667 - accuracy: 0.0966\n",
      "Epoch 10/30\n",
      "208480/208480 [==============================] - 9s 43us/step - loss: 0.6667 - accuracy: 0.0966\n",
      "Epoch 11/30\n",
      "208480/208480 [==============================] - 9s 41us/step - loss: 0.6667 - accuracy: 0.0966 0s - los\n",
      "Epoch 12/30\n",
      "208480/208480 [==============================] - 8s 41us/step - loss: 0.6667 - accuracy: 0.0966\n",
      "Epoch 13/30\n",
      "208480/208480 [==============================] - 8s 36us/step - loss: 0.6667 - accuracy: 0.0966\n",
      "Epoch 14/30\n",
      "208480/208480 [==============================] - 9s 42us/step - loss: 0.6667 - accuracy: 0.0966\n",
      "Epoch 15/30\n",
      "208480/208480 [==============================] - 8s 37us/step - loss: 0.6667 - accuracy: 0.0966\n",
      "Epoch 16/30\n",
      "208480/208480 [==============================] - 11s 50us/step - loss: 0.6667 - accuracy: 0.0966\n",
      "Epoch 17/30\n",
      "208480/208480 [==============================] - 8s 40us/step - loss: 0.6667 - accuracy: 0.0966\n",
      "Epoch 18/30\n",
      "208480/208480 [==============================] - 7s 35us/step - loss: 0.6666 - accuracy: 0.0966\n",
      "Epoch 19/30\n",
      "208480/208480 [==============================] - 8s 36us/step - loss: 0.6667 - accuracy: 0.0966\n",
      "Epoch 20/30\n",
      "208480/208480 [==============================] - 8s 38us/step - loss: 0.6666 - accuracy: 0.0966\n",
      "Epoch 21/30\n",
      "208480/208480 [==============================] - 8s 37us/step - loss: 0.6666 - accuracy: 0.0966\n",
      "Epoch 22/30\n",
      "208480/208480 [==============================] - 9s 42us/step - loss: 0.6667 - accuracy: 0.0966\n",
      "Epoch 23/30\n",
      "208480/208480 [==============================] - 7s 36us/step - loss: 0.6666 - accuracy: 0.0966\n",
      "Epoch 24/30\n",
      "208480/208480 [==============================] - 7s 34us/step - loss: 0.6666 - accuracy: 0.0966\n",
      "Epoch 25/30\n",
      "208480/208480 [==============================] - 7s 32us/step - loss: 0.6666 - accuracy: 0.0966\n",
      "Epoch 26/30\n",
      "208480/208480 [==============================] - 7s 33us/step - loss: 0.6666 - accuracy: 0.0966\n",
      "Epoch 27/30\n",
      "208480/208480 [==============================] - 7s 32us/step - loss: 0.6666 - accuracy: 0.0967\n",
      "Epoch 28/30\n",
      "208480/208480 [==============================] - 7s 33us/step - loss: 0.6272 - accuracy: 0.3011\n",
      "Epoch 29/30\n",
      "208480/208480 [==============================] - 7s 32us/step - loss: 0.5751 - accuracy: 0.5687\n",
      "Epoch 30/30\n",
      "208480/208480 [==============================] - 7s 32us/step - loss: 0.5751 - accuracy: 0.5687\n",
      "Test fraction correct (NN-Score) = 0.57\n",
      "Test fraction correct (NN-Accuracy) = 0.57\n"
     ]
    }
   ],
   "source": [
    "X_train = train_X\n",
    "y_train = train_Y.values\n",
    "X_test = test_X\n",
    "y_test = test_Y.values\n",
    "\n",
    "\n",
    "y_train = one_hot_encode_object_array(y_train)\n",
    "y_test = one_hot_encode_object_array(y_test)\n",
    "\n",
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(units =3*8 , activation = 'relu', input_dim = 68))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units = 3*4, activation = 'relu'))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units = 3*2, activation = 'relu'))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(units = 3, activation = 'tanh'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'adam', loss = 'hinge', metrics=['accuracy'])\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "classifier.fit(X_train, y_train, batch_size = 32, epochs = 30)\n",
    "\n",
    "score, accuracy = classifier.evaluate(X_test, y_test, batch_size=16, verbose=0)\n",
    "print(\"Test fraction correct (NN-Score) = {:.2f}\".format(score))\n",
    "print(\"Test fraction correct (NN-Accuracy) = {:.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing ANN Parameters: Activation for Output Layer & Loss Function <a class=\"anchor\" id=\"op1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The activation function for the output layer was initially tanh. However, tanh is more appropriate for binary classification instead of multi-class classification. As such, we changed the activation for output layer from tanh to softmax. Softmax outputs produce a vector that is non-negative and sums to 1. It is useful for mutually exclusive categories, making it highly ideal for our use case.\n",
    "\n",
    "The loss function was initially hinge. However, hinge is a loss function used for binary classification. Once again, we tuned the parameter to be most ideal for multi-class classification. As such, we used categorical_crossentropy, a loss function used for multi-class classification. Categorical crossentropy will compare the distribution of the predictions (the activations in the output layer, one for each class) with the true distribution, where the probability of the true class is set to 1 and 0 for the other classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "208480/208480 [==============================] - 8s 39us/step - loss: 2.6630 - accuracy: 0.5066\n",
      "Epoch 2/30\n",
      "208480/208480 [==============================] - 8s 36us/step - loss: 0.9879 - accuracy: 0.5382\n",
      "Epoch 3/30\n",
      "208480/208480 [==============================] - 9s 41us/step - loss: 0.8573 - accuracy: 0.5713\n",
      "Epoch 4/30\n",
      "208480/208480 [==============================] - 9s 44us/step - loss: 0.8350 - accuracy: 0.5725\n",
      "Epoch 5/30\n",
      "208480/208480 [==============================] - 8s 38us/step - loss: 0.8230 - accuracy: 0.5742\n",
      "Epoch 6/30\n",
      "208480/208480 [==============================] - 7s 35us/step - loss: 0.8197 - accuracy: 0.5743\n",
      "Epoch 7/30\n",
      "208480/208480 [==============================] - 7s 34us/step - loss: 0.8188 - accuracy: 0.5741\n",
      "Epoch 8/30\n",
      "208480/208480 [==============================] - 7s 34us/step - loss: 0.8167 - accuracy: 0.5746\n",
      "Epoch 9/30\n",
      "208480/208480 [==============================] - 7s 33us/step - loss: 0.8156 - accuracy: 0.5751\n",
      "Epoch 10/30\n",
      "208480/208480 [==============================] - 7s 33us/step - loss: 0.8146 - accuracy: 0.5748 0s - loss: 0.8146 - \n",
      "Epoch 11/30\n",
      "208480/208480 [==============================] - 7s 33us/step - loss: 0.8136 - accuracy: 0.5754\n",
      "Epoch 12/30\n",
      "208480/208480 [==============================] - 7s 33us/step - loss: 0.8132 - accuracy: 0.5752\n",
      "Epoch 13/30\n",
      "208480/208480 [==============================] - 7s 33us/step - loss: 0.8124 - accuracy: 0.5756\n",
      "Epoch 14/30\n",
      "208480/208480 [==============================] - 7s 33us/step - loss: 0.8109 - accuracy: 0.5758\n",
      "Epoch 15/30\n",
      "208480/208480 [==============================] - 7s 33us/step - loss: 0.8106 - accuracy: 0.5763\n",
      "Epoch 16/30\n",
      "208480/208480 [==============================] - 7s 33us/step - loss: 0.8084 - accuracy: 0.5769\n",
      "Epoch 17/30\n",
      "208480/208480 [==============================] - 7s 33us/step - loss: 0.8045 - accuracy: 0.5784\n",
      "Epoch 18/30\n",
      "208480/208480 [==============================] - 7s 33us/step - loss: 0.7959 - accuracy: 0.5903\n",
      "Epoch 19/30\n",
      "208480/208480 [==============================] - 7s 33us/step - loss: 0.7941 - accuracy: 0.5929\n",
      "Epoch 20/30\n",
      "208480/208480 [==============================] - 7s 33us/step - loss: 0.7922 - accuracy: 0.5957\n",
      "Epoch 21/30\n",
      "208480/208480 [==============================] - 7s 33us/step - loss: 0.7917 - accuracy: 0.5970\n",
      "Epoch 22/30\n",
      "208480/208480 [==============================] - 7s 33us/step - loss: 0.7900 - accuracy: 0.5980\n",
      "Epoch 23/30\n",
      "208480/208480 [==============================] - 7s 33us/step - loss: 0.7897 - accuracy: 0.6004\n",
      "Epoch 24/30\n",
      "208480/208480 [==============================] - 7s 33us/step - loss: 0.7882 - accuracy: 0.6013\n",
      "Epoch 25/30\n",
      "208480/208480 [==============================] - 7s 33us/step - loss: 0.7871 - accuracy: 0.6018 1s - loss: 0 - ETA: 0s - loss: 0.7\n",
      "Epoch 26/30\n",
      "208480/208480 [==============================] - 7s 33us/step - loss: 0.7868 - accuracy: 0.6020\n",
      "Epoch 27/30\n",
      "208480/208480 [==============================] - 7s 33us/step - loss: 0.7854 - accuracy: 0.6032 \n",
      "Epoch 28/30\n",
      "208480/208480 [==============================] - 7s 33us/step - loss: 0.7850 - accuracy: 0.6037\n",
      "Epoch 29/30\n",
      "208480/208480 [==============================] - 7s 33us/step - loss: 0.7850 - accuracy: 0.6026\n",
      "Epoch 30/30\n",
      "208480/208480 [==============================] - 7s 36us/step - loss: 0.7847 - accuracy: 0.6038\n",
      "Test fraction correct (NN-Score) = 0.78\n",
      "Test fraction correct (NN-Accuracy) = 0.60\n"
     ]
    }
   ],
   "source": [
    "X_train = train_X\n",
    "y_train = train_Y.values\n",
    "X_test = test_X\n",
    "y_test = test_Y.values\n",
    "\n",
    "\n",
    "y_train = one_hot_encode_object_array(y_train)\n",
    "y_test = one_hot_encode_object_array(y_test)\n",
    "\n",
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(units =3*8 , activation = 'relu', input_dim = 68))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units = 3*4, activation = 'relu'))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units = 3*2, activation = 'relu'))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(units = 3, activation = 'softmax'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "classifier.fit(X_train, y_train, batch_size = 32, epochs = 30)\n",
    "\n",
    "score, accuracy = classifier.evaluate(X_test, y_test, batch_size=16, verbose=0)\n",
    "print(\"Test fraction correct (NN-Score) = {:.2f}\".format(score))\n",
    "print(\"Test fraction correct (NN-Accuracy) = {:.2f}\".format(accuracy))\n",
    "\n",
    "ann_acc = accuracy*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tuned ANN model returns a higher accuracy of 0.6, as compared to untuned accuracy at 0.57. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[back to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Logistics Regression classifier <a class=\"anchor\" id=\"model2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic function, which this model is based on, is an S-shaped curve that takes any real number as input and outputs y, where 0<y<1. This algorithm models the the probablity of either one of the outcomes (ie damage_grade), and works by estimating Beta values from training data such that the error in probabilities predicted is minimised. Although it is mostly used for binary classification, it can be modified to be used for more than 2 outcomes.\n",
    "\n",
    "We will first employ the default logistics regression classifier. We first set the class_weight to balanced, to give more weight to minority classes. Later on, we will tune the solvers to optimize model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The standard accuracy score is:  0.4345849081943938\n",
      "The recall score is:  0.4345849081943938\n",
      "The matthew's correlation coefficient is:  0.13683648271691962\n"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "\n",
    "#Build the model\n",
    "clf = LogisticRegression(class_weight='balanced') # We set classweight=balanced to give more weight to minority class\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(train_X, train_Y)\n",
    "\n",
    "#test the model\n",
    "preds = clf.predict(test_X)\n",
    "\n",
    "#heat map for confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(10,7))\n",
    "sb.heatmap(confusion_matrix(test_Y, preds), annot=True, fmt='d')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "print(\"The standard accuracy score is: \", accuracy_score(test_Y.values, preds))\n",
    "print(\"The recall score is: \", sklearn.metrics.recall_score(test_Y.values, preds, average='micro'))\n",
    "print(\"The matthew's correlation coefficient is: \", sklearn.metrics.matthews_corrcoef(test_Y.values, preds))\n",
    "\n",
    "log_reg_acc = round( accuracy_score(test_Y.values, preds) * 100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimzing Logistic Regression Parameters: Solvers <a class=\"anchor\" id=\"op2\"></a>\n",
    "\n",
    "For logistic regression, there is no single criticial hyperparameter to tune. However, tuning solvers can sometimes give better performance. From the scikit documentation (https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression) , the 5 solvers are: “liblinear”, “newton-cg”, “lbfgs”, “sag” and “saga”. \n",
    "\n",
    "The “lbfgs” solver is used by default for its robustness. The “lbfgs” solver is recommended for use for small data-sets but for larger datasets its performance suffers. Each solver has its merits and demerits which are listed on the scikit documentation, and we tested all 5 solvers.\n",
    "\n",
    "Based on our trial and erorr, we found the liblinear solver returns highest accuracy. This is likely because logistic regression model using this solver behave as multiclass classifiers, which is appropriate for our use case.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The standard accuracy score is:  0.5621150783753189\n",
      "The recall score is:  0.5621150783753189\n",
      "The matthew's correlation coefficient is:  0.2216200301771318\n"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "\n",
    "#Build the model\n",
    "clf = LogisticRegression(class_weight='balanced', solver = 'liblinear') # We set classweight=balanced to give more weight to minority class\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(train_X, train_Y)\n",
    "\n",
    "#test the model\n",
    "preds = clf.predict(test_X)\n",
    "\n",
    "#heat map for confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(10,7))\n",
    "sb.heatmap(confusion_matrix(test_Y, preds), annot=True, fmt='d')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"The standard accuracy score is: \", accuracy_score(test_Y.values, preds))\n",
    "print(\"The recall score is: \", sklearn.metrics.recall_score(test_Y.values, preds, average='micro'))\n",
    "print(\"The matthew's correlation coefficient is: \", sklearn.metrics.matthews_corrcoef(test_Y.values, preds))\n",
    "\n",
    "log_reg_acc = round( accuracy_score(test_Y.values, preds) * 100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the optimal solver, the accuracy for logistic regression significantly improved from 0.43 to 0.56."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[back to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: K Nearest Neighbours <a class=\"anchor\" id=\"model3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K Nearest Neighbours is based on the idea of proximity, that is, data points with similar features are more likely to have the same output (ie damage_grade). It works by computing the distance between data points and creating clusters that minimises distance between them, iterating a few times to achieve the best results. We will need to test a few values of K to find the K that produces the best predictions.\n",
    "\n",
    "For KNN model, the most critical hyperparameter is number of neighbours, n_neighbors. n_neighbors have test value between 1 and 21. We tested out the accuracy of KNN model with n_neighbors of different values and found that n_neighbours = 10 gives highest accuracy. You may refer to appendix for KNN models with other n_neighbour values we attempted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The standard accuracy score is:  0.7101360296233764\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 10)\n",
    "knn.fit(train_X, train_Y)\n",
    "Y_pred = knn.predict(test_X)\n",
    "\n",
    "print(\"The standard accuracy score is: \", knn.score(test_X, test_Y))\n",
    "\n",
    "knn_acc = round(knn.score(test_X, test_Y) * 100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[back to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4: Decision Tree <a class=\"anchor\" id=\"model4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method teaches the model to make decisions based on the given data, by learning which features are more important in making the decision. It can be used for both regression and classification, but for this purpose, we will be using it to do classification. At each node of the tree, the model will make binary splits in such a way that minimises the cost function (such as Gini, for classification), making it a greedy algorithm.\n",
    "\n",
    "We test out a default decision tree model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodness of Fit of Model for Test Dataset\n",
      "Classification Accuracy: 0.6599834999328485\n",
      "Recall score:  0.6599834999328485\n",
      "Matthew's correlation coefficient:  0.388353774211266\n"
     ]
    }
   ],
   "source": [
    "# decision tree with train data\n",
    "dectree = DecisionTreeClassifier () # create the decision tree object\n",
    "dectree.fit(train_X, train_Y.values)      # train the decision tree model\n",
    "\n",
    "# predict responses\n",
    "y_train_pred = dectree.predict(train_X)\n",
    "y_test_pred = dectree.predict(test_X)\n",
    "\n",
    "\n",
    "# check goodness of model with test data\n",
    "print(\"Goodness of Fit of Model for Test Dataset\")\n",
    "print(\"Classification Accuracy:\", dectree.score(test_X, test_Y.values))\n",
    "print(\"Recall score: \", sklearn.metrics.recall_score(test_Y.values, y_test_pred, average='micro'))\n",
    "print(\"Matthew's correlation coefficient: \", sklearn.metrics.matthews_corrcoef(test_Y.values, y_test_pred))\n",
    "\n",
    "decision_tree_acc = round(dectree.score(test_X, test_Y.values) * 100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing Decision Tree: Max_depth <a class=\"anchor\" id=\"op4\"></a>\n",
    "\n",
    "The first parameter to tune is max_depth, which implies how deep the tree can be. The larger the max_depth value, the deeper the tree, the more splits it has. That means it is able to capture more information about our data set. \n",
    "\n",
    "Based on our trial and error, we found that max_depth = 20 gave highest accuracy. At larger max_depth values, our model likely overfits - where it  predicts all of the train data but does not generalize the findings for new data. At smaller max_depth values, our model does not predict the train data as accurately. The optimal max_depth value of 20 allows the model to predict the train data and generalize the findings for new data reasonably well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodness of Fit of Model for Test Dataset\n",
      "Classification Accuracy: 0.6966673701579018\n",
      "Recall score:  0.6966673701579018\n",
      "Matthew's correlation coefficient:  0.44222634287193313\n"
     ]
    }
   ],
   "source": [
    "# decision tree with train data\n",
    "dectree = DecisionTreeClassifier(max_depth = 20)  # create the decision tree object\n",
    "dectree.fit(train_X, train_Y.values)      # train the decision tree model\n",
    "\n",
    "# predict responses\n",
    "y_train_pred = dectree.predict(train_X)\n",
    "y_test_pred = dectree.predict(test_X)\n",
    "\n",
    "\n",
    "# check goodness of model with test data\n",
    "print(\"Goodness of Fit of Model for Test Dataset\")\n",
    "print(\"Classification Accuracy:\", dectree.score(test_X, test_Y.values))\n",
    "print(\"Recall score: \", sklearn.metrics.recall_score(test_Y.values, y_test_pred, average='micro'))\n",
    "print(\"Matthew's correlation coefficient: \", sklearn.metrics.matthews_corrcoef(test_Y.values, y_test_pred))\n",
    "\n",
    "decision_tree_acc = round(dectree.score(test_X, test_Y.values) * 100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[back to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 5: Random Forest Classifier <a class=\"anchor\" id=\"model5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model can be used for both classification and regression, and is built on top of the Decision Tree method (Method 4). It workd by randomly selects data subsets, creates decision trees on each subset, and then vote for the best solution. The more trees there are in the forest, the more robust the model. While Random Forest can eliminate the problem of overfitting that a normal Decision Tree might experience, it is slower and might be difficult to interpret.\n",
    "\n",
    "We first employ a random forest classifier with default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 2 ... 2 2 2]\n",
      "The standard accuracy score is:  0.7114023138466261\n",
      "The recall score is:  0.7114023138466261\n",
      "The matthew's correlation coefficient is:  0.4595153215600796\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_jobs=4, \n",
    "                             random_state=0,\n",
    "                             criterion=\"gini\",\n",
    "                             n_estimators=100,\n",
    "                             verbose=False)\n",
    "\n",
    "clf.fit(train_X, train_Y.values)\n",
    "preds = clf.predict(test_X)\n",
    "print(preds)\n",
    "\n",
    "print(\"The standard accuracy score is: \", accuracy_score(test_Y.values, preds))\n",
    "print(\"The recall score is: \", sklearn.metrics.recall_score(test_Y.values, preds, average='micro'))\n",
    "print(\"The matthew's correlation coefficient is: \", sklearn.metrics.matthews_corrcoef(test_Y.values, preds))\n",
    "\n",
    "cm = pd.crosstab(test_Y.values, preds, rownames=['Actual'], colnames=['Predicted'])\n",
    "\n",
    "#heat map for confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(10,7))\n",
    "sb.heatmap(cm, annot=True, fmt='d')\n",
    "plt.show()\n",
    "\n",
    "random_forest_acc = round( accuracy_score(test_Y.values, preds) * 100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, without hyperparameter tuning for Random Forest, this model already yields highest accuracy among all 5 models. In section 3, we will deep dive into hyperparameter tuning to further improve the Random Forest model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[back to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection <a class=\"anchor\" id=\"select\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>71.140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>KNN</td>\n",
       "      <td>71.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>69.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ANN</td>\n",
       "      <td>59.954721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>56.210000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model      Score\n",
       "2        Random Forest  71.140000\n",
       "3                  KNN  71.010000\n",
       "0        Decision Tree  69.670000\n",
       "4                  ANN  59.954721\n",
       "1  Logistic Regression  56.210000"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = pd.DataFrame({\n",
    "    'Model': [ 'Decision Tree', 'Logistic Regression', 'Random Forest','KNN','ANN'],\n",
    "    'Score': [ decision_tree_acc,log_reg_acc, random_forest_acc, knn_acc, ann_acc]})\n",
    "\n",
    "models.sort_values(by='Score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model with the highest accuracy is Random Forest. Random Forest is a classifcation model that comprises of many decision trees, and likely works well in this use case where the data set has many variables. \n",
    "\n",
    "Even though Random Forest and KNN have very similar accuracy scores, we must note that Random Forest has more hyperparameters we have yet to tune, unlike KNN which main hyperparameter to tune is number of neighbours. This means that Random Forest has even more potential for further tuning to improve its accuracy.\n",
    "\n",
    "Random Forest also has a short run time, especially compared to ANN model. \n",
    "\n",
    "With its high accuracy and short run time compared to the other models, we will select Random Forest as our model of choice. In the next part, we will employ various techniques to improve the accuracy of the Random Forest model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[back to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix <a class=\"anchor\" id=\"appendix\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Model with n_neighbours varied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN Model at lower bound value of n_neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The standard accuracy score is:  0.6916214193894975\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(train_X, train_Y)\n",
    "Y_pred = knn.predict(test_X)\n",
    "\n",
    "print(\"The standard accuracy score is: \", knn.score(test_X, test_Y))\n",
    "\n",
    "knn_acc = round(knn.score(test_X, test_Y) * 100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN Model at n_neighbours =11, where optimal n_neighbours = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The standard accuracy score is:  0.7098482377544559\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 11)\n",
    "knn.fit(train_X, train_Y)\n",
    "Y_pred = knn.predict(test_X)\n",
    "\n",
    "print(\"The standard accuracy score is: \", knn.score(test_X, test_Y))\n",
    "\n",
    "knn_acc = round(knn.score(test_X, test_Y) * 100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[back to top](#top)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
